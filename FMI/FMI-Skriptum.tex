%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass[a4paper]{article}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{cite}
\usepackage{color}
\usepackage{listings}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{array}
\usepackage{multirow}

\newcommand{\tb}[1]{\textbf{#1}}
\newcommand{\entails}[1]{\models{#1}}
\definecolor{gray}{rgb}{0.8,0.8,0.8}
\pagenumbering{arabic}
\DeclareGraphicsRule{.tif}{png}{.png}
{‘convert #1 ‘dirname #1‘/‘basename #1 .tif‘.png}
%opening


\lstset{
	language=inform,
	frame=shadowbox,
	rulesepcolor=\color{gray},
	captionpos=b
}

%%% useful macros for Turing machines:
\newcommand{\blank}{\sqcup}
\newcommand{\ssym}{\triangleright}
\newcommand{\esym}{\triangleleft}
\newcommand{\halt}{\mbox{h}}
\newcommand{\yess}{\mbox{``yes''}}
\newcommand{\nos}{\mbox{``no''}}
\newcommand{\lmove}{\leftarrow}
\newcommand{\rmove}{\rightarrow}
\newcommand{\stay}{-}
\newcommand{\diverge}{\nearrow}
\newcommand{\yields}[1]{\stackrel{#1}{\rightarrow}}
\newcommand{\TPL}{T_{PL}}

\newcommand{\HALTING}{\mbox{\bf HALTING}}

\begin{document}

	\title{\textbf{Formale Methoden der Informatik}\\ Course 185.291 \\WS2013}
	\author{Lectors: Pichler, Egly \\ Author: Georg Abenthung \\ Matr. Nr.: 0726213
	}
	\date{Oct. 2013}

	\maketitle
	%no page number on first page
	\thispagestyle{empty}
	\abstract{This document are personal notes to the provided Course-Material.}
	\newpage
	
%	\begin{figure}
%		\centering
%		\includegraphics[width=10cm]{tuwien_logo}
%	\end{figure} 
	
	
	\newpage
\section{Computation and Computability}
\subsection{Problems}
\begin{itemize}
  \item {Problem has a name}
  \item {Infinite set of instances}
  \item {Question}
  \item {Answer (yes/no on decision question)}
  \item There are diferent types of problems
  \item In FMI most problems are decision problems.
  \item A program should solve a problem in a mechanical way! (Can be solved by
  a computer or ,,An algorithm can solve the problem''
  \item Alg. should be simple, understandable(shareable), should terminate and
  should work on ALL possible instances of the problem
  \item Given a problem P, can we write a program that is an algorithm for P
  \item Input is a single String or a list of values (def.)
  \item Our programming language is called \textbf{SIMPLE}
  \item If there doesn't exist a SIMPLE program, there doesn't exist a Java
  program (or Turing machine program) either
 \end{itemize}\begin{framed}Church Turing Thesis:\\ Any algorithm can be programmed
in SIMPLE
\end{framed}


Goldbach's Conjecture can't be proved. (Every even integer greater than 2 is
the sum of two primes) The algorithm to check never terminates until we find a
counterexample. If we would have a program, which could tell us, if an algorithm
terminates, we could answer the Goldbach Conjecture. BUT: It doesn't exist.

\subsection{Halting problem (Page 20)}
We want to show, that the Halting problem is undecidable, and then show, that
the assumption leads to a contradiction.\\

A program will be applied to a program as input string. \\
' \ldots prime \\
'' \ldots doubleprime \\

$\Pi''_h $ \ldots speak ,,Pi sub h doubleprime'' \\

This prove goes back to Allan Touring.
\subsection{Page 23}
Reachable-Code Problem is similiar to prove than Halting problem.
Put some code at the end of the program (Infinite Loop !?!?)

\subsection{Page 24}
Decidability implies Semi-Decidability but not vice-versa.

The halting problem is semi-decidable!
Semi-Decidability: You'll never know if you haven't calculated far enough, or
you'll never reach an end!


\subsection{Page 26}
There are two sources of infinity.
It will halt for instances which reach all lines of code, but the algorithm will
never stop, when there's dead code.

\subsection{Page 27}
Cantor's enumeration. Give an enumeration to two indefinite sets.

\subsection{Page 28}
compare to Sequential Calculus by Goedel

\section{Complexity of Problems and Algorithms}

\subsection{Scope of complexity theory}
Notation of Papadimitriou will be used in this section

\subsection{Page 4}
Does there exist a path between u and v.\\
Outer repeat loop is repeated lineearly often.\\
Inner loop also linearly often. At the end it's cubic runtime.

\subsection{Page 5}
The answer to all question: It doesn't really matter in context of complexity
theory.

\subsection{Page 9}
the ,,Big O Notation'' is used in this lecture. $O(f(n))$\\
Other notions are also reasonable, but we - in complexity theory - use the
Big-O-Notation

Complexity theory doesn't work with \textbf{finite} number of Instances for a
problem $\mathcal{P}$. THe Problem must be generalized before.

\subsection{Page 11 - Notion of O, $\Omega$, and $\Theta$}
the big $\Omega$ notation is the reverse of the O notation

$ O(n^3) $ might be $ 0.5n^3-17n^2 $\ldots


\subsection{Page 12 - Efficiently Solvable}
Can a problem be solved in Polynomial (\textbf{P} or \textbf{PTIME}) time.

\subsection{Page 14}
The Vertexes in a boolean circuit are it's ,,Gates''\\

\subsection{Page 19}
We don't care if we can solve the Problem $\mathcal{P}$ in $O(n)$ or $O(n^4)$.
The only important thing is that we can solve it in \textbf{P}

\subsection{Page 22  - from Boolean Formulas to Circuits}
The boolean Input-Gates correspond with the variables used in the formula.

\subsection{Page 26 - The class NP}
The big problem is, that the search space is Exponential.
THere are $2^n$ possible assignments.

Although we can often find a solution to a problem $\mathcal{P}$ with good
heuristics.

\subsection{Page 29}
$INSTANCES(\mathcal{P})$\ldots Boolean Formulas\\
$CERT$\ldots Models (truth assignments)

\subsection{Page 30 - Definition of the class NP}
see Course material

\subsection{Page 35}
Transform the TSP from an Optimization Problem to a decision problem by
introducing a bound.



\section{Reductions}

This is the most important tool in complexity theory. It's used to compare the
complexity of two problems.

\subsection{Page 3 - Basic Idea}

Recall the TSP.
Compare TSP as a \textbf{Decision Problem} (a.k.a. TSP(D)) vs. the TSP as an
\textbf{optimization Problem}

Construct a:
\begin{itemize}
\item Decision problem using an Alg. for Opt.Problem: Does there exist a tour
which fits in a specific budget (Budget might be calculatet by a TSP-Opt-Alg.)
\item Solution for the Opt.Probl using a Alg. for decision Problem: Use
Binary search.
\end{itemize}

\subsection{Page 4}
\paragraph{We have the following setting:}
\begin{itemize}
  \item Problem A: new Problem
  \item Problem B: old and easy solution available
  \item Use Problem B to solve the new Problem A
  \item we say: A is reduced to problem B. (or $A \leq B$)
\end{itemize}

$ A \stackrel{R}{\Longrightarrow} B $

We assume, that the reduction $R$ is feasible in time. We don't want to talk
about the complexity of the reduction $R$, we want to talk about the complexity
of A and B
\paragraph{Another setting:}
\begin{itemize}
  \item Problem A: known as hard
  \item Problem B: new
  \item Problem B is also hard. (If there is no efficient method for A there
  also doesn't exist a simple solution for B)
\end{itemize}

Complexity. Theory is more interested in the second setting (the negative
example).

\subsection{Page 8}
 \begin{center}
	\fbox{\begin{minipage}{15em}
            \begin{tabbing}
            \hspace*{2em}\= \kill % set the tabbings
 
            R: \> $A \longrightarrow B$ \\
               \> $x \longmapsto R(x)$ \\
               \> $x \in A \Leftrightarrow  R(x) \in B$

            \end{tabbing}
     \end{minipage}}
\end{center}

\subsection{Page 9}

Recall what CNF (Conjunctive Normal Form on PL0) means. The SAT Problem is
NP-Complee (without proof). If only CNF is allowed, the Problem is still
NP-Hard. The same if you would allow any arbitrary structure (e.g. DNF).

with 3-SAT we once more reduce the complexity, by reducing the length of the
clauses to 3. The problem is still as complex.

The reduction from SAT to 3-SAT is complicated and not covered in this lecture.

\subsection{Page 10}
2-SAT is easily solvable.


\subsubsection{Page 10 - Independent Set}
Two points should not be adjacent\ldots

The problem gets hard, when you try to find a set of a size $K$

\subsection{Page 11}

2-SAT $\stackrel{R}{\Longrightarrow}$ REACHABILITY



\subsection{Page 12ff - Example of solving the 2-SAT problem}
We can construct 6 literals (3 variable $x_1, x_2, x_3$)

 \begin{center}
	\fbox{\begin{minipage}{15em}
            \begin{tabbing}
            \hspace*{2em}\= \kill % set the tabbings
 
            $\alpha \rightarrow \beta \equiv \neg \alpha \vee \beta$ \\
            $(\alpha \vee \beta) \equiv \neg \alpha \rightarrow \beta $ \\
            $(\alpha \vee \beta) \equiv \neg \beta \rightarrow \alpha $\\


            \end{tabbing}
     \end{minipage}}
\end{center}


\subsection{Page 16ff - more complex example}

This is a typical way of proving something.


INDEPENDENT SET $\leq$ 3-SAT (Ind.Set at least as hasr than 3-SAT)

3-SAT $\stackrel{R}{\Longrightarrow}$ INDEPENDENT SET
We assume 3-SAT old and hard.

\paragraph{Page 18} Choose one literal per clause and try to set it to true. Be
sure not to assign true to a variable ad it's negation.


\paragraph{Page 19} Divide the equivalence. WE start with the direction from
right to left. Assume that $R(x)$ is a positive instance of B and then show,
that $x$ is a positive instance of A.

K \ldots number of klauses

\paragraph{Page 20} find a truth assignment that $x \in A$
We set those variables true which occur positively in the independent set.



\paragraph{Page 21} Now we have to prove the other direction.

Showing (ii) is trivial we have chosen m literals of m triangles.

Showing (i) is more complicated. Choose an arbitrary pair of vertices and show
it's not adjacent. But it's simpler by choosing an indirect proove.





\subsection{Page 22}

the red stuff is important.

ANY(!) two NP-Problems can be reduced to each other. (e.g. the reduction from
3-SAT to INDEPENDENT SET) 

$ \mathcal{P}'_{in NP} \leq 3-SAT \leq IND-SET$ or also $ \mathcal{P}'_{in NP}
\leq IND-SET \leq 3-SAT$

NP is the Class of problems, that can be solved with succinct Certificates. (It
only requires polynomial time to find a whitness)

So, if a problem is for example reducable to SAT we know, that the Problem is
not harder than NP.

$P \subseteq NP \subseteq PSPACE \subseteq EXPTIME$


\subsection{Page 24}

 \begin{center}
	\fbox{\begin{minipage}{15em}
            \begin{tabbing}
            \hspace*{2em}\= \kill % set the tabbings
 			\> $\mathcal{P}' \leq \mathcal{P} \subseteq P$\\
            \> $x \stackrel{R} {\rightarrow} R(x)$ \\
            \end{tabbing}
     \end{minipage}}
\end{center} 


\subsection{Page 26}
Informal Proof

\subsection{Page 27}
The formal solution
 \begin{center}
	\fbox{\begin{minipage}{15em}
            \begin{tabbing}
            \hspace*{2em}\= \kill % set the tabbings
            \> $A \stackrel{R} {\rightarrow} B $ \\
            \> $x \mapsto R(x) $ \\
            \> $x \in A \Leftrightarrow R(x) \in B $
            \end{tabbing}
     \end{minipage}}
\end{center} 






\section{NP-Completeness}

\subsection{Page 3}

2-SAT can be solved in P-Time by reducing it to reachability. SAT and 3-SAT are
NP-Complete (without Proof here.)


\subsection{Page 5}
THis is only a rough proof-sketch, not the whole proof.

\subsection{Page 6}
We are only allowed to assume, that $\mathcal{P}$ has a polynomiable decidable
certificate relation. (Else $\mathcal{P}$ would not be arbitrary.)


\subsection{Page 8}
WE have to show that $SAT \leq 3-SAT$

$\phi $ and $\psi$ must not be logically equivalent.

\subsection{Page 11 - Some NP-Problems}

\subsection{Page 12}
Left: Independent set
Idea: Take the complement graph (on the right side)

With this idea an reduction can be constructed.

\subsubsection{Page 17}


 \begin{center}
	\fbox{\begin{minipage}{15em}
            \begin{tabbing}
            \hspace*{2em}\= \kill % set the tabbings
            3-SAT: \\
            $\phi$ = \> $C_1 \wedge \ldots \wedge C_n $ \\
            \> $ C_i = (l_{i1} \vee l_{i2} \vee l_{i3}) $ \\
        
            \end{tabbing}
     \end{minipage}}
\end{center} 

\subsection{Page 18}
Wheter you make a question more or less restrictive, you can't say beforehand,
if solving the problem becomes easier or harder. 

\subsection{Page 20}
We have good SAT-Solvers, so sometimes it's good to reduce a problem to SAT
first.

\subsection{Page 26}
\subparagraph{Certificate:} Truth assignment is a Certificate in the SAT world.
Mapping is a Certivicate in the Graph world.

\subsection{Page 28}

Instead of a clause-based forumla we could also used a rule-based formula:
$p_1 \wedge p_2 \wedge p_3 \rightarrow p_4  = \neg p_1 \vee \neg p_2 \vee \neg
p_3 \vee p_4$

\subsection{Page 30}
The other direction.

The more subformulas we have, the harder it's getting to prove, that there is a
model.



\section{Other important complexity classes}

\subsection{Page 6}

This implementation is not recursive\ldots

\subsection{Page 7}

Time complexity is one exponation higher than it's space complexity.


\subsection{Page 8 - PSPACE}

We assume, that PSPCE is a bigger class than NP. (not prooved yet.)

\subsection{Page 10 - Tica Tac Toe (TTT)}

No branching for player 1. We only choose one move, which could lead to a
winning-strategy.

Exists-For-All alternation is typical for PSPACE:\\
,,Does there exist \textbf{A} move for
player one, so that for \textbf{ALL} moves of P2 \ldots exists \textbf{A} move
for P1 so that for \textbf{ALL} moves for P2 \ldots''

Don't check all constellations of P1 in a move. Check them one after another.
So the steps of the tree is polynomial bounded. THis immediately gives us a
PSPACE upperbound.

\subsection{Page 11}
The travelling space is exponentially big, but we are not forced to use it.
THis is a property of the game not a property of complexity theory.

\subsection{Page 14}
$P \subseteq PTIME$ \ldots you don't have more time to access the memory more
often \ldots

\subsection{Page 14}
We have two problems, which need PTIME, so we can don't address more than PSPACE
memory.

\subsection{Page 15 - EXPTIME}

,,2 to the power of a polynom.''



\section{Turing machines}

Some proofs are almost impossible to encode in SIMPLE. some are easier to
implement in Turing machines.

\subsection{Page 4 }
Transition table of the turing machine.

\subsection{Page 5}
One sided infinitely tape.

$(s, \ssym{}, 1001)$ means (the cursor position, the symbols on the left side
of the cursor including the cursor, the alphabet on the right side )

We can store a constant amount of information in the states of the turing
machine.


\subsection{Page 8}
the ,,h'' state is used, if we want to produce output. Else the states are
,,yes'' or ,,no''

\subsection{Page 10}

yields with $M^k$ means a state can be reached in $k$ steps.

\subsection{Page 11}
Start and blank symbol are never in the alphabet $\Sigma$

Definition: If a string is element of a Language L, the the TM should output
yes.

\subsection{Page 18}
3 tapes are needed: Input-Tape (RO), Work-Tape (RW), Output-Tape (WO)

\subparagraph{Implement a RO-Tape:} only allow to overwrite with the same
symbol.
\subparagraph{Implement a WO Tape:} only allow the cursor to move to the right.



\subsection{Page 23}

with NTM we have a \textbf{transition relation} instead of a \textbf{transition
function.}

\subsection{Page 25}

If we have at least one ,,YES''-answer, we say, the machine accepts the input.\\
To say no, \textbf{ALL} leavers must have the answer ,,NO''


\section{SAT Problems - Preparatory Concepts}

\subsection{Page 5}
This type of figure is called \tb{Cactus Plot}
In 2002 they solved approx. 40 problems with 2010 Software they solved approx.
170 problems. With hardware of 2010 and problems defined in 2009.

Theese are real-world problems like hardware optimization of IBM.

We use SAT-solvers because they are good and provided for free in Public Domain.


\subsection{Pabge 19}

$ \not\leftrightarrow = XOR$

\subsection{Page 21}
THis kond of translation is called \tb{Structure preserving translation}.

\subsection{Pae 31}
The tree shows all ISF's (Immediate subformulas).


\subsection{Page 33}
\subparagraph{Mapping:} We map all variables to truth-values

There are other representation. Here the \tb{iff} representation is choesn by
Uwe Egly.

\subsection{Page 34}
$\models$ \ldots ,,satifies''

\subsection{Page 35}
The first formula in the example: This is used to prove if the \tb{Modus Ponens}
is sound.

\subparagraph{Modus Ponens:} is an inference rule. from two formulas ,,$\phi$''
and ,,$\phi \rightarrow \psi$'' derives ,,$\psi$''

\subparagraph{Modus Tonens:} from two formulas ,,$\neg \phi$'' and ,,$\phi
\rightarrow \psi$'' we derive ,,$\psi$''

Because we can see here $I$ as an ,,Eigenvariable'' this proof is correct. It
is shown \tb{forall}( $\forall$). So we don't have to introduce an additional 
$\forall$-Quantifier


\subsection{Page 37}
An empty clause is an equivalence for  \tb{falsum}.\\
$W$ \ldots Knowledgebase\\ $\phi$ \ldots query

\subsection{Page 38}
We reduce to \tb{Satisfiability} to reuse SAT-Solver.
The reduction can be done quick (e.g. with a python script.)


\subsection{Different normal forms and translation procedures}

\subsection{Page 44 - NNF translation}
These are the rules to translate a formula into \tb{NNF}. These rules must be
applied in this order.

\subsection{CNF translation}
From the \tb{NNF} we can simply create \tb{CNF} by applying these rules.

\subsection{Page 48 - Tseitin translation}
NFT \ldots Normal form translation

\subsection{Page 53}

$q$ is labelled twice (with $l_1$ and $l_2$) because this
is a non-optimized version.


\subsection{Page 63}
YOu can only show the existing of models, BUT you don't get the same models for 
$\phi$ and $\delta(\phi)$

SFO \ldots Subformula occurence

\subsection{Page 64}

NOT logically equivalent, nly satisfiability-equivalence!








\section{SAT-Problems - Techniques for modern SAT Solvers}

\subsection{Page 2 - Cactus Plot}
What are the reasons for that improvements?

These tests hav been run on a modern hardware with solvers from 2002-2010. So,
the better results are just because of the better implementations of the
SAT-solvers.

In modern solvers not only one step backtracking. THe solvers jump high above\ldots

\subsection{Page 5}
\subparagraph{DLL} \ldots ,,Davis-Loveland-Lodgement'' the authors of the first
paper (also called DPLL )

\subsection{Page 6}
\subparagraph{CDCL} - Conflict Driven Clause Learning solvers

\subsection{Page 7}
Basic idea of solvers.

\subsection{Page 14}
Red-Arrows ($\leftarrow$) mean: Conflict between these two clauses under the
partial assignment. WE are now in a deadlock stage. We can't put away the
conflict.

We now apply the first stop criterium. WE now try to backtrack chronologically.


\subsection{Page 18}

After a few backtracks we get a assignment which satifies all clauses.

\subparagraph{UNIT-Rule} THe blue clauses on the slides are unit (c must be 1
to satisfy this clause) the unit rule detects that and sets c to true. The same
happens to atom d.

This is called \tb{Boolean Constraint Propagation}.

\subsection{Page 19}
Now we have a model. Because every clause is satisfied


\subsection{Page 20}
The status of the clauses change over time, like shown in this table. After
each decision the status change.


\subsection{Page 22}

Horn Clauses: Every clause has at most one positive atom. (But can have many
atoms)

\subsection{Page 23 - Heuristics to select truth assignments}
\subsection{Page 24 - DLIS}

Quite an expensive heuristic. Here we go to the approach to satisfy clauses
quickly.

\subsection{Page 25 - Jeroslov-Wang Heuristic}

You try to get Unit-clauses quickly, because they are not far away of conflicts.
You want to get short clauses here quickly.

\subsection{Page 26 - Basic SAT Algorithm}

\subparagraph{PCP} Boolean Constraint Propagation

\subsection{Page 30 - }
Each node in the IG is a variable assignment.

dl (Decision Level) 0 for unit clauses \ldots You don't have a choice. YOu have
to chose the correct answer for the remaining variable.


\subsection{Page 31}

(sic!) $\neg v_1$ should be $ v_{1}^d $ (dual) here

\subsection{Page 32}
In \tb{S2} we have a UNIT-Clause. We can assign the UNIT value.

Keep in mind: on the slides, we often only see parial IG's!

\subsection{Page 33ff - Example of Implication Graph (IG) GRASP approach}

\subsection{Page 37}
We have a conflict graph with the conflict node $\kappa$

\subsection{Page 39}
It's conflict driven, because we start to learn, after a conflict $\kappa $
occured.

\subsection{Page 43}
How can we learn a clause out of this conflict?

decision levels are increased whenever there is made a new decision

The conslict clause is the negated decision clause.

(sic!) at the bottom we should flip $x_1$ instead to flip $x_6$

\subsection{Page 45}
By backtrack to decision level 6, the PCB automatically flips $x_1$ because of
the newly learned rule. Which auomatically makes $\neg x_1$ becomes unit.


\subsection{Page 48}
We have a conflict $\kappa'$ but we don't have a decision ($x_1$ was unit, not
decided.) Now we could try to go back chronologically to an higher dl. But this
is not a good idea. WE go back to dl 3 because there we have the chance to
change an assignment, else the clause will remain conflicting. The only one
which makes the learned clause $c_11$ non conflicting.


\subsection{Page 53 - first UIP scheme}

\subsection{Page 54}
cut is a partition of the vertice-set. One node of the edge is in S and the
other node is in T

\subparagraph{Page 55}

These 3 cut edges are the 3 possibilieties to cut out the choice-nodes. You have
to choose one of them. Each cut brings up a different conflict clause. Which one
to choose?

\subparagraph{Page 58}

All clauses shown in the previous slides where \tb{Asserting clauses}.
Actual SAT-solvers only work with asserting clauses.

\subparagraph{Page 59 - UIP's}
\subparagraph{UIP} \ldots Unique implication point

\subparagraph{Page 60}

Choose the cut (see Page 55) according to the first UIP.

\subparagraph{PAge 61}

only one decision from the highest level will be taken to the second last
decision level, to get a unique.

\subparagraph{Page 65}
In the res the $x_5$ has been cancelled like mentioned in the previous slides.

\subparagraph{Page 68 - VSIDS}
After ading learned clauses, you don't go back and recalculate, you simply add
the new rule. To avoid overflows you simply divide the scores by 2 (or any
other number\ldots but 2 is good because it's a bit-shift).




\section{RECAP: First order logic and theories}

\subsection{Page 6}
THe ground term is enough to represent the natural Numbers. $c = 0$ and $f(c)
\ldots = of c$

\subsection{Page 10 - Semantics of the first order logic.}

\subsection{Page 17}
$p(x) \not\equiv p(y)$ because they have a different $\alpha$.

\subsection{Page 23}
We want to overload the ,,$\entails{}$'' symbol here.


\subsection{Page 26 - First Order Theory}

We will build a resolver for an ,,restricted Theory''.

\subsection{Page33}
$\doteq$ \ldots see next slide

\subsection{Page 34f}
Read: $[\ldots] \rightarrow [\ldots]$

Description on the next slide!

\subsection{Page 36}
line 2: the left hand side of the implication must be true\\
line 3: right hand side of the implication must be false\\
\ldots

\subsection{Page 39f}
Rule 6 is a protection rule so that you can't use cons(a, b) to atoms. (See
remrks on the next slide.)


\subsection{Page 42}

Rule 2-5: conjunctions of the left hand side splitted and all assumed tro
(since rule 1 must hold))



\section{A desision procedure for equality logic}
https://tuwel.tuwien.ac.at/mod/resource/view.php?id=166539

\subsection{Page 7}

Identifier \ldots a variable.\\
so: $term ::= [a|b|c$ or $x|y|z \ldots]$

\subsection{Page 9}
First we want to get rid of the constants. After that we have extended the
language by a new variable for each constant.

\subsection{Page 12ff}
The variables are the nodes of the grapg $G^E$

\subsection{Page 17}
The graph looks the same whether the (In)Equalities are connected by $\vee$ or
$\wedge$.

\subsection{Page 18}
The graph is NOT a representation o the formula.

\subsection{Page 19}
Simple circle when you \textbf{only} repeat $v_1$ (see examples on next slide)


\subparagraph{Page 30}
The example is an example of \textbf{E-unsatisfiability}

\subsection{Page 32}

We throw something away. Make the formula shorter.

Step 4: we replace $true \wedge smthg = smthg$ etc.

\subsection{Page 37}
After apply the algorithm, redreaw the graph $G^E$ and apply algorithm again.

\subsection{Page 40}
$B_t$ is a conjunction of Transitivity constraints.

\subsection{Page 43}

$G_{NP}^E$ \ldots NP stands for ,,non polar''. 

\subsection{Page 49}

Make it chordal: We trinagulate the graph.

\subsection{Page 50}
There is a $P-TIME$ Algorithm to make a graph chordal.


\subsection{Page 56 - From E-logic to propositional logic}

The overall reduction algorithm like explained in detail in the previous
slides..


\subsection{Page 57}
Use the POLAR version and not the non-polar version for the analysis.
(Improvement, if you want to implement that stuff\ldots).


\subsection{Page 59}

You shoud be able to answer ,,Why is a chordal graph better?''




\section{Eqaulity Logic and Uninterpreted Function Symbols}

\subsection{Page 6}
You loose all function ? except \textbf{function congruence}.

\subsection{Page 7}

\subparagraph{Why?} When you say, that a property holds for $\phi'$, then this
property holds also for the special property of ,,$+$'' (or $\phi$)
You prove something on the left for all functions of type \textbf{F}. You show a
more general theorem, when you replace interpreted by uninterpreted function
values.


\subsection{Page 8}
Even simplify the proof search (which is the crucial stuff\ldots)

\subsection{Page 9}

\subparagraph{Remark Definition:} Constants are special function symbols with
arity 0.

\subparagraph{Remarks:} Everything except the equality ($ \doteq $) is
uninterpreted.

\subsection{Page 11}

Loopbound: $i<2$ \ldots this is a constant, so you know, when the loop stops.


\subsection{Page 13}
Tse multiplier $*$ is - still - an interpreted function. We want to replace it
with an uninterpreted function.

\subsection{Page 14} You have to deal with overflow in machine architecture.

The binary multiplication $*$ is replaced by the binary function $G$

\subsection{Page 15} we now discuss, who to get rid of the uninterpreted
symbols, we created in the previous slides.

\subsection{Page 17}
FC \ldots functionality constraints

\subsection{Page 18}
If you have a constant, you associate it with it's value.


\subsection{Page 21 - Ackermann reduction (AR)) with more than one funciton
symbols} \subsection{Page 23} This shows how ,,flat'' is computed.
\subsection{Page 24} Read it as a conjunction over the component-wise
equalities.

\subsection{Page 25}: The $in \doteq in$ can be simplified to $true$.

We can decide the E-formula by converting it to a propositional formula and
decide it then.


\subsection{Page 31}
The red stuff line 4: Put the negation iinto the formula and translate the
implication $( a \rightarrow b )$ to $(\neg a \vee b)$ 



\section{Deductive Verification of Programs 2013-11-13}
\subparagraph{Lector: }Gernot Salzer

\subsection{Page 5}
Building compilers is nowadays much more easy, since there are automatic
generations.

\subsection{Page 8}
\subparagraph{Model Checking:} e.g. the programm must look in a specific time
for user input. This can be checked using Model checking.


\subsection{Page 9}
Program is not adequate: It's difficult to know for a computer, what the
customer means.

\subsection{Page 10}
You only take a look at the properties, you are interested in. Not to all the
auxiliary variables (e.g. Program for multiplication: you only verify the
output, and not that a aux.var. which is used in the programm behaves in a
specified manner.)

\subsection{Page 11}
\subparagraph{semantics of $\TPL$}: Normally we don't have a formal smantic of
a programming lang. The computer doesn't understand, what the prog. is about. We
only have examples in prosa.

\subsection{Page 14: $\TPL$-Syntax}

\subsection{Page 16}
We overload the meaning of $\mathcal{P}$, $\mathcal{E}$, $\mathcal{V}$ etc\ldots

\subsection{Page 18}
Sysntactically correctness is a preconstraint for Semantic correctness.

,,A language understanding is a statistical phenomenon.'' The first sentence on
this slide became a Meta-Semantics since it was introduced by Chomsky.

\subsection{Page 19}
We are interested in the red statements in this lecture.

\subsection{Page 21}
Input-States are an assignment of values to variables.

\subsection{Page 22}
In $\TPL$ we don't have indeterminism, so we don't have several outputs for one
input.

\subsection{Page 23 - Program States}
In our language $\TPL$ a prog.-state is symply a mapping from variables to
values.

\subsection{Page 24}
Set of configurations: We have those two types of configurations.\\
$(\mathcal{P} x \mathcal{S})$ \ldots not final program state.\\
$\mathcal{S}$\ldots final state



\subsection{Page 25} there might be no successor configuration. For determinism
we have at most one!

\subsection{Page 26} for the abort-stmt. no transition is defined.

The stuff with the line is an ,,if\ldots then\ldots else''

Sequential composition: add an arbitr. Programm after $p$.

\subsection{Page 27}
Square-barckets ($[\ldots]$) is used to denote the semantics of an expression.

Expressions do not change a state! They only have a result.


\subsection{Page 29} Note! ,,$[.]$'' is overloaded!\\
e.g. the evaluation of $[u]$\ldots is a Unary function.\\
the evaluation of $[b]$\ldots is a Binary function.\\

\subsection{Page 31}
We have a state $\sigma$ and we want to evaluate the expression $[.]$ with
the given state.


\subsection{Page 31}
Syntax is inside $[.]$ and semantics is outside $[.]$

\subsection{Page 33 - Example program run. WHILE}

Sequential composition always means we have a subcomputation.

We have now proven, that the result recording to the semantics and inputs is
correct.

\subsection{Page 34 - Example for ABORT}


\subsection{Page 35 - Infinite program run.}

You end up with the same configuration than above, that means we have a infinite
program.

\subsection{Page 36} the star means we have arbitrary many steps for this
transition.



\section{Deductive Verification of Programs 2013-11-18}

\subsection{Page 3}
We alwas have to know what exactly we're verifying.

\subsection{Page 9 - Definition of semantics of a program}
The transition relation is the definition of the semantics of a program.

\subsection{Page 11 - Difference between $[1]$ and $1$}
$[1]$ \ldots used in the programming language.\\
$1$ \ldots the mathematical semantic of $[1]$

\subsection{Page 14}
Note the difference with sequential composition.\ldots

THis is a high level view.

\subsection{Page 15ff - Proof of if then else}
Step 3: apply the semantics definition.


\subsection{Page 17}
The natural Semantic is a little bit easier than Structural operational
semantics (SOS). You don't need so much side computations.

\subsection{Page 22}
Only if the program terminates we take care of the output-states $S_{out}$

\subparagraph{Partially correctness:} We don't care about termination.

For a determination proof you have to show, that the states will decrease. So
the lines of codes to be executed must decrease.

Beware: you don't want a operating system to terminate.



\subsection{Page 26}
The four different kinds of calculi are similar.

\subsection{Page 27}
Our quantifiers work only with the states.

\subsection{Page 29}
F-states: all states, that are a model of thet formula $F$ (\ldots all states
tha make the formula F true).

Not every set of states can be described by a formula.

\subsection{Page 30}
,,whenever'' here means ,,if''.

Mathematicians don't have the term ,,terminate'' They say  a function is
,,defined''

\subsection{Page 31}
$\{1\}$\ldots this is always true (The semantics of ,,$1''$ is true). (Set of
all states)

\subsection{Page 36}
Think of your parents. Mother says ,,no'', father says ,,yes'' $\rightarrow$
Mother is stronger.


\section{Deductive Verification of Programs 2013-11-20}
gefehlt
\begin{itemize}
	\item Hoare calculus
	\item Weakest (liberal) precondition
	\item Strongest postcondition
\end{itemize}

\section{Deductive Verification of Programs 2013-11-25}
This is the last lecture of the block 3.


\subsection{Page 12}
,,Shift up- and downwards''

\subsection{Page 16}
We can ommit the pats we know from the premise.

\subsection{Page 17}
From line 1 to 2: We can ommit the existential-operator since d is not used in
the formula.

Block down: Use strongest postcondition to show that left implies the right\ldots

\subsection{Page 18 - Hoare Calculus}
read bottom-up

\subsection{Page 20}

This is the short variant.

\subsection{Page 22 - Loops}
The idea is to unwrap the loop $i$-times, so that we don't have a loop anymore.

\subsection{Page 23} the guess must be verified.

\subsection{Page 23}
Now compute the weakest precondition


\subsection{Page 29}
$c$ must be constant only within the LOOP.

\subsection{Page 32}
the more premises we have, the (potentially) easier it gets to make the proof.

$wht'' \rightarrow wht'''$\ldots the loop will only iterate once more if $e$
is true.


\subsection{Page 33}
For most cases it hols, that you find $t$ b looking at the loop-condition.


\section{Block 4 - Errors: Know thy enemy - 2013-11-27}
Lector: H.Veith

Essentially every program is a single long formula.

\subsection{Limitations of machine Reasoning}

You can write a program which determines if a prog. terminates with the possible
answers: ,,YES'', ,,NO'', ,,DON'T KNOW''

\subsection{System ANalysis by Model Checking}
Logical specification is a concrete property like ,,Termination''. Does the
prog. terminate?

The problem is to get the state description. We are talking of a
,,\textbf{State Explosion}''. The graphs are getting extraordinary large. (You
may have (e.g.) $2^{2^{32}}$) nodes in a graph.


\section{Block 4 - Temporal Logic Model CHecking}

\subsection{Page 7}
AG \ldots stands for Always\\
EF \ldots possible\\
AF \ldots eventually

\subsection{Page 9 - LTL}
LTL \ldots linear time logic\\
XXa \ldots a must hold in the second next state.\\
XFa \ldots from the next state x must hold in the future


It's simple to convert LTL into FO, but quite difficult to do it in the other
way round.

$G(b \vee Xb)$ \ldots the holes between b is true can be max. the size of one.\\
$GFc$ \ldots at each state $Fc$ must hold.


\subsection{Page 19 - Families of CTL's}
There are different families of CTL. And variants.

\section{PDF-File with definitions.}
\subsection{Page 7}

$CTL^*$ is a generalization of $CTL$ and $LTL$

$Fp$ \ldots path formulas (you need a path to tell if the statements holds)\\
$AXp$ \ldots state formula (you can evaluate this formula with only one state)

Each state-formula is also a path formula.

\subsection{Page 10 - Semantics of a formula}

Read these rules as a programm which tell you what you can do\ldots

\subsection{Page 13}
in $CTL$ only AX, AG AU, AF and EX, EG, EU, EF are allowed, but not (e.g.) EGF.
But you can combine those operations. You always have \textbf{state formulas}.
THis is the big advantage of $CTL$


\subsection{Page 14}

In $LTL$ you only have \textbf{Path formulas}. $LTL$ is very useful to find
counterexamples.

 
\section{Block 4 - Temporal Logic, Model Checking (2.12.2014)}

\subsection{<model checking is fast\ldots}
$K, s \entails{} \phi $ \ldots $O(|K|*|\phi |)$

\subsection{Symbolic Model checking}
In the 90's it seemed, that a graph is not the best datastructure to describe a
problem. The number of nodes exploded (for a normal size C-Program.)

They decided to use \textbf{Binary Decision Diagrams} for Symbolic model
checking systems.

\section{Simulation and abstraction (02.12.2013)}
\subsection{Page 2}
\subparagraph{Preorder:} $A \leq B \wedge B \leq A $ does not imply that $ A =
B$ (unlike in total order\ldots)

\subsection{Page 3}
Spoiler \ldots tries to find a counterexample\\
Duplicator \ldots does the same action than the spoiler and tries to answer.

\subsection{Page 4}
The spoiler plays on $S$, the duplicator plays on $I$

The color denotes a value of a property of a specific state. Two nodes with the
same color have the same value, but are not the same state.


\subsection{Page 5}
have the same propositions means ,,have the same color''

\subsection{Page 10}

$a,b,c,d$ are labels and not properties here.

The both graphs are not similiar. But they are bisimilar.


\subsection{Page 12}
$M_2$ has a strategy to simulate $M_1$. The duplicater
just always has to go to the ,,good'' b. But they are \textbf{NOT} bisimilar.
The spoiler good go to the Model $M_2$ and goes to the ledt b.

Spoiler goes to the b on the left. In the next round, the spoiler changes the
sode of the game ($M_1$). Now the duplicator i on $M_2$ and on the ,,bad b''.

The duplicator needs to change sides to win.

Formula: For all reachable b's there exists a d. (This does not hold on
$M_2$) \ldots $AXEXd$ or $AX(b \rightarrow EXd)$

NB: There must be a ,,E'' in the formula.

\subsection{Page 15}
These two formulas are important for verifying systems.

We want to verify $M_1$ and construct an $M_2$ which simulates $M_1$. We model
check a simplified version of $M_1$.

\subsection{Page 16}
Although you can do more in $N$ it is the smaller one of these graphs.


\subsection{Page 20}
After simplifacation you get a state-base with three states (instead of all
integers.) This minimizes the number of states (now 3) dramatically.

But you loose a lot of information: $h(7) = h(9) = a_{odd}$ therefore 7 and 19
are equivalent, because they are mapped to the same abstract states.

\subsection{Page 24}
The spoiler plays on $M$ and the duplicator plays on $M_r$






\end{document}
